{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Lennard Jones Potential \n",
    "\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lennard Jones potential is among the simplest analytical potentials, it is a \n",
    "two-body potential where the interaction between a pair of atoms is given by\n",
    "$$\n",
    "V(r) = 4 \\epsilon \\left[ \\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^{6} \\right]\n",
    "$$\n",
    "\n",
    "Where $r$ is the distance between the atoms $\\sigma$ is a parameter that determines the \n",
    "location of the minimum and $\\epsilon$ determines the depth of the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Energy of a pair of atoms.\n",
    "\n",
    "Implement a function that takes the distance `r`, `sigma` and `epsilon` and returns the Lennard Jones \n",
    "potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lj_energy(r, sigma, epsilon):\n",
    "    E = 0 # calculate the Lennard-Jones energy\n",
    "    return E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often best to work with functions that take arrays as that allows for avoiding \n",
    "slow for-loops. So test whether your function works with an `numpy` array - otherwise \n",
    "change it so that it does;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lj_energy(np.array([1, 2, 3]), 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Energy of an `Atoms` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function `calculate` that takes an `Atoms`-object, `sigma` and `epsilon` and returns the \n",
    "total energy according to the Lennard Jones expression. \n",
    "\n",
    "Hint: First create an array that contains the distance between all pairs of atoms, \n",
    "you can use the [`pdist`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html)\n",
    "function from scipy to do this. Then pass that to your `get_lj_energy` function and sum \n",
    "all the terms together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(atoms, sigma, epsilon):\n",
    "    d = 0 # Find the distances between all atoms\n",
    "    E = 0 # Calculate the Lennard-Jones energy\n",
    "    return E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Lennard Jones with Object Oriented Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code we have written so far is functional; we have created functions that take some input and return output - without \n",
    "any type of state/memory. Yet, the inputs we have passed are not really of the same type - the `Atoms` object is \n",
    "really the variable and `sigma` and `epsilon` are parameters of the function. \n",
    "\n",
    "If is often beneficial to create classes in these types of situations and is very \n",
    "commonly done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LennardJones:\n",
    "\n",
    "    def __init__(self, sigma, epsilon):\n",
    "        self.sigma = sigma\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def get_lj_energy(self, r):\n",
    "        # Calculate the Lennard-Jones energy using the class attributes \n",
    "        # self.sigma and self.epsilon. \n",
    "        pass\n",
    "\n",
    "    def calculate(self, atoms):\n",
    "        # Same logic as before, but now we use the class method get_lj_energy.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Computing forces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to calculate not only the energy but also the force on each atom. The components \n",
    "of the forces are given by\n",
    "$$\n",
    "F_i^\\alpha = -\\frac{\\partial E}{\\partial x_i^\\alpha}\n",
    "$$\n",
    "\n",
    "Where $i$ indicates the atom and $\\alpha$ denotes either the $x$, $y$ or $z$ dimension. \n",
    "\n",
    "This can be applied to the Lennard Jones expression, but it is cumbersome and \n",
    "more difficult to implement than the potential itself - but if you want to try \n",
    "you can. Note that the potential is not given directly in terms of the coordinates, \n",
    "but rather in terms of the distance between atoms, so that needs to be taken into account.\n",
    "\n",
    "This exercise is **optional** and probably best left as an extra for the interested. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lennard Jones with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stepping stone to implementing neural network based potentials we will first \n",
    "look at implementing the Lennard Jones potential using Pytorch.\n",
    "\n",
    "To do so, we should replace all `numpy` or `scipy` functions in our implementation \n",
    "with `torch` functions and any use of arrays from `numpy` should be replaced \n",
    "with `torch.tensor`.\n",
    "\n",
    "One of the main benefits of doing this is that we can calculate forces using \n",
    "*automatic differentiation* the same technique that enables training of neural networks. \n",
    "\n",
    "In the cell below you should fill out the left out code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LennardJonesTorch:\n",
    "\n",
    "    def __init__(self, sigma=1.0, epsilon=1.0):\n",
    "        self.sigma = sigma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def atoms_to_tensor(self, atoms):\n",
    "        return torch.tensor(atoms.positions, requires_grad=True)\n",
    "    \n",
    "    def get_lj_energy(self, r):\n",
    "        # Calculate the Lennard-Jones energy using the class attributes \n",
    "        # self.sigma and self.epsilon.\n",
    "        r6 = r**6\n",
    "        r12 = r6**2\n",
    "        return 4 * self.epsilon * (self.sigma/r12 - self.sigma/r6)\n",
    "    \n",
    "    def get_forces(self, energy, positions):\n",
    "        return -torch.autograd.grad(energy, positions, retain_graph=True)[0]\n",
    "\n",
    "    def calculate(self, atoms):\n",
    "        # Convert the positions to a tensor\n",
    "        positions = self.atoms_to_tensor(atoms)\n",
    "        return self.forward(positions)\n",
    "\n",
    "    def forward(self, positions):\n",
    "        # Calculate the pairwise distances\n",
    "        d = torch.pdist(positions)\n",
    "\n",
    "        # Calculate the Lennard-Jones energy\n",
    "        E = torch.sum(self.get_lj_energy(d))\n",
    "        F = self.get_forces(E, positions)\n",
    "\n",
    "        # Return the energy and forces\n",
    "        E = E.detach().numpy() # Convert back to numpy\n",
    "        F = F.detach().numpy() \n",
    "        return E, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "\n",
    "LJT = LennardJonesTorch()\n",
    "\n",
    "atoms = Atoms('H2', positions=[[0.0, 0.0, 0.0], [1.105, 0.0, 0.0]])\n",
    "\n",
    "energy, forces = LJT.calculate(atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Using atomic forces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common use case of atomic forces is local optimization or 'relaxation'. \n",
    "Here the energy is minimized by moving the atoms according to the forces, \n",
    "this is analagous to a ball rolling down a hill to find a \n",
    "position that minimizes the gravitational potential energy. \n",
    "\n",
    "ASE makes this very easy, the code below converts your `LennardJonesTorch` \n",
    "to an `ase` `Calculator` such that it can interface with the rest of the functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9902696910139173\n"
     ]
    }
   ],
   "source": [
    "from imlms import get_calculator_from_class\n",
    "\n",
    "LJT = get_calculator_from_class(LennardJonesTorch)(sigma=1.0, epsilon=1.0)\n",
    "\n",
    "atoms = Atoms('H2', positions=[[0.0, 0.0, 0.0], [1.105, 0.0, 0.0]])\n",
    "atoms.calc = LJT\n",
    "E = atoms.get_potential_energy()\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this section on [optimizers](https://wiki.fysik.dtu.dk/ase/gettingstarted/tut02_h2o_structure/h2o.html#optimizers) \n",
    "from the `ase` documentation and relax a small molecule, e.g. H2 with your Lennard Jones potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Step     Time          Energy          fmax\n",
      "BFGS:    0 19:42:05       -0.320337        1.158029\n",
      "BFGS:    1 19:42:05       -0.361161        1.312428\n",
      "BFGS:    2 19:42:05       -0.921519        2.041011\n",
      "BFGS:    3 19:42:05       55.298954      974.487533\n",
      "BFGS:    4 19:42:05       -0.923220        2.028761\n",
      "BFGS:    5 19:42:05       -0.924897        2.016337\n",
      "BFGS:    6 19:42:05       -0.752559        8.517609\n",
      "BFGS:    7 19:42:05       -0.970548        1.472894\n",
      "BFGS:    8 19:42:05       -0.990140        0.939655\n",
      "BFGS:    9 19:42:05       -0.997803        0.528593\n",
      "BFGS:   10 19:42:05       -0.999924        0.092418\n",
      "BFGS:   11 19:42:05       -1.000000        0.007274\n",
      "BFGS:   12 19:42:05       -1.000000        0.000113\n",
      "-0.9999999998888873\n"
     ]
    }
   ],
   "source": [
    "from ase.optimize import BFGS\n",
    "\n",
    "atoms = Atoms('H2', positions=[[0.0, 0.0, 0.0], [1.5, 0.0, 0.0]])\n",
    "atoms.calc = LJT\n",
    "\n",
    "optimizer = BFGS(atoms, trajectory='H2.traj')\n",
    "optimizer.run(fmax=1e-3)\n",
    "\n",
    "print(atoms.get_potential_energy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Trainable Lennard Jones Potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to do now is to make the parameters `sigma` and `epsilon` learnable from \n",
    "data. This will enable us to fit the Lennard Jones potential as best as possible to \n",
    "a given dataset. \n",
    "\n",
    "To do this we will change a few things from our `LennardJonesTorch` class, \n",
    "we will make another called `LennardJonesModule` with these changes.\n",
    "\n",
    "1. `LennardJonesModule` should *inherit* from `torch.nn.Module`. \n",
    "2. The parameters should be set as `torch.nn.Parameter` instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LennardJonesModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, sigma=1.0, epsilon=1.0):\n",
    "        super().__init__()\n",
    "        self.sigma = torch.nn.Parameter(torch.tensor(sigma))\n",
    "        self.epsilon = torch.nn.Parameter(torch.tensor(epsilon))\n",
    "\n",
    "    def atoms_to_tensor(self, atoms):\n",
    "        return torch.tensor(atoms.positions, requires_grad=True)\n",
    "    \n",
    "    def get_lj_energy(self, r):\n",
    "        # Calculate the Lennard-Jones energy using the class attributes \n",
    "        # self.sigma and self.epsilon.\n",
    "        r6 = r**6\n",
    "        r12 = r6**2\n",
    "        return 4 * self.epsilon * (self.sigma/r12 - self.sigma/r6)\n",
    "    \n",
    "    def get_forces(self, energy, positions):\n",
    "        return -torch.autograd.grad(energy, positions, retain_graph=True)[0]\n",
    "\n",
    "    def calculate(self, atoms):\n",
    "        # Convert the positions to a tensor\n",
    "        positions = self.atoms_to_tensor(atoms)\n",
    "        return self.forward(positions)\n",
    "\n",
    "    def forward(self, positions):\n",
    "        # Calculate the pairwise distances\n",
    "        d = torch.pdist(positions)\n",
    "\n",
    "        # Calculate the Lennard-Jones energy\n",
    "        E = torch.sum(self.get_lj_energy(d))\n",
    "        F = self.get_forces(E, positions)\n",
    "\n",
    "        # Return the energy and forces\n",
    "        E = E.detach().numpy() # Convert back to numpy\n",
    "        F = F.detach().numpy() \n",
    "        return E, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the functionality that we get from inheriting from `torch.nn.Module` is \n",
    "the easy access to all the parameters of our class - one way is shown below;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma 1.0\n",
      "epsilon 1.0\n"
     ]
    }
   ],
   "source": [
    "ljm = LennardJonesModule()\n",
    "\n",
    "for name, parameter in ljm.named_parameters():\n",
    "    print(name, parameter.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ase.calculators.lj import LennardJones\n",
    "\n",
    "def get_lennard_jones_dataset(n=25):\n",
    "    epsilon = np.random.normal(loc=1.0, scale=0.25)\n",
    "    sigma = np.random.normal(loc=1.0, scale=0.25)\n",
    "    \n",
    "    r0 = 2**(1/6) * sigma\n",
    "\n",
    "    R = np.linspace(0.8, 2.0, n)\n",
    "    data = []\n",
    "    for r in R: \n",
    "        E = 4 * epsilon * ((sigma/r)**12 - (sigma/r)**6)\n",
    "        X = torch.tensor([[0, 0, 0], [r, 0, 0]])\n",
    "        data.append((X, E))\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
