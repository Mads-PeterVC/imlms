{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9421b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture install\n",
    "try:\n",
    "  import imlms\n",
    "  print('Already installed')\n",
    "except:\n",
    "  %pip install git+https://github.com/Mads-PeterVC/imlms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(install.stdout.splitlines()[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "c7ba406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91448907",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from imlms.potentials.load_carbon_data import get_carbon_cluster_data, get_atomic_dataset, get_invariances_examples, to_atoms\n",
    "from agox.utils.plot import plot_atoms, plot_cell\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "09a36d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example: Atomic Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54541766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atomic_fingerprint(positions, cutoff=5.0, n=16, sigma=0.5):\n",
    "    R = cdist(positions, positions).reshape(len(positions), len(positions), 1)\n",
    "    r0 = np.linspace(0, cutoff, n).reshape(1, 1, n)\n",
    "    z = np.exp(-(R-r0)**2/ sigma**2) * np.cos(np.pi/2 * r0 / cutoff) * (r0 < cutoff)\n",
    "    return z.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4265fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain, ring = get_invariances_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "labels = ['Chain', 'Ring']\n",
    "for ax, atoms, label in zip(axes, [chain, ring], labels):\n",
    "    plot_cell(ax, atoms.cell, collection_kwargs={'alpha': 0})\n",
    "    plot_atoms(ax, atoms)\n",
    "    for atom in atoms:\n",
    "        ax.text(atom.x, atom.y, atom.index, fontsize=8, color='black', ha='center', va='center')\n",
    "    ax.set_title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "acdc47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Previously we have used descriptors of configurations, but we can also make \n",
    "descriptors of atoms - or as it is typically called descriptors of the atomic \n",
    "environment.\n",
    "\n",
    "The `atomic_fingerprint` function above computes such atomic environment descriptors.\n",
    "\n",
    "The cell below computes these fingerprint for the two example structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_fingerprints = atomic_fingerprint(ring.positions, n=32, sigma=0.25)\n",
    "chain_fingerprints = atomic_fingerprint(chain.positions, n=32, sigma=0.25)\n",
    "\n",
    "print(\"Ring\", ring_fingerprints.shape)\n",
    "print(\"Chain\", chain_fingerprints.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "3bad1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "From the shapes we see that for each example structure we have 6 vectors, corresponding to the number of atoms, with 16 entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "89deefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Like before we can use the dot product similarity measure to compare the different atomic descriptors.\n",
    "From the figure above we can tell that \n",
    "\n",
    "- For the chain, atoms 4 and 5 are at either end of the chain. Which are very similar environments, so we would expect the fingerprints of these these two atoms to be very similar. \n",
    "\n",
    "- Atoms 1 and 2 of the chain are both in the center, so we expect them to be very similar.\n",
    "\n",
    "- Atom 1 of the chain is in the middle which is quite different from atom 4 at the end, so the similarity between their descriptors should be lower.\n",
    "\n",
    "- All atoms of the ring structure are similar, because of its symmetry, so the similarity between environments should be high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c09dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_45 = dot_product_similarity(chain_fingerprints[4], chain_fingerprints[5])\n",
    "print(f\"Chain 4-5 {chain_45:0.4f}\")\n",
    "\n",
    "chain_12 = dot_product_similarity(chain_fingerprints[1], chain_fingerprints[2])\n",
    "print(f\"Chain 1-2 {chain_12:0.4f}\")\n",
    "\n",
    "chain_14 = dot_product_similarity(chain_fingerprints[1], chain_fingerprints[4])\n",
    "print(f\"Chain 1-4 {chain_14:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "2993f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "As before we can make a similarity matrix to get a visual representation of the similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3134780",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_ring = np.zeros((6, 6))\n",
    "D_chain = np.zeros((6, 6))\n",
    "D_ring_vs_chain = np.zeros((6, 6))\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        D_ring[i, j] = dot_product_similarity(ring_fingerprints[i], ring_fingerprints[j])\n",
    "        D_chain[i, j] = dot_product_similarity(chain_fingerprints[i], chain_fingerprints[j])\n",
    "        D_ring_vs_chain[i, j] = dot_product_similarity(ring_fingerprints[i], chain_fingerprints[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed146a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(9, 4), layout='constrained')\n",
    "\n",
    "c = ax[0].imshow(D_ring, cmap='viridis', vmin=0.9, vmax=1.0)\n",
    "ax[0].set_title('Ring')\n",
    "\n",
    "ax[1].imshow(D_chain, cmap='viridis', vmin=0.9, vmax=1.0)\n",
    "ax[1].set_title('Chain')\n",
    "\n",
    "ax[2].imshow(D_ring_vs_chain, cmap='viridis', vmin=0.9, vmax=1.0)\n",
    "ax[2].set_title('Ring vs Chain')\n",
    "\n",
    "colorbar = fig.colorbar(c, ax=ax, orientation='horizontal')\n",
    "\n",
    "for a in ax[0:1]:\n",
    "    a.set_xlabel('Atom index')\n",
    "    a.set_ylabel('Atom index')\n",
    "\n",
    "ax[2].set_xlabel('Chain Atom index')\n",
    "ax[2].set_ylabel('Ring Atom index')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "e898307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Try to understand why they look like this\n",
    "\n",
    "You can also play around with the parameters `n` and `sigma` for the `atomic_fingerprint`."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "582d4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise: Learning atomic properties"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "401cfa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "With descriptors of atomic environments we can build models that learn atomic properties. \n",
    "\n",
    "For illustrative purposes we will build a model that predicts the number close neighbours an atom has. \n",
    "\n",
    "The cell below loads the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cart, Y = get_atomic_dataset(8, threshold=2.0)\n",
    "\n",
    "X_fingerprint = torch.vstack([torch.tensor(atomic_fingerprint(x)).float() for x in X_cart])\n",
    "y_tensor = torch.tensor(Y).flatten().float()\n",
    "\n",
    "print(f\"{X_cart.shape = }\")\n",
    "print(f\"{X_fingerprint.shape = }\")\n",
    "print(f\"{y_tensor.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae90608",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 2\n",
    "fig, axes = plt.subplots(3, 5, figsize=(5*sz, 3*sz), layout='constrained')\n",
    "\n",
    "for example_index, ax in enumerate(axes.flat):\n",
    "    atoms = to_atoms(X_cart[example_index])\n",
    "\n",
    "    plot_cell(ax, atoms.cell, collection_kwargs={'alpha': 0})\n",
    "    plot_atoms(ax, atoms)\n",
    "\n",
    "    for i, atom in enumerate(atoms):\n",
    "\n",
    "        ax.text(atom.x, atom.y, Y[example_index][i], fontsize=8, color='black', ha='center', va='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "e74dca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we define a model, very much like we have done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordinationNumberModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vector_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(torch.nn.Linear(vector_dim, hidden_dim)) # vector_dim -> hidden_dim\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(hidden_dim, hidden_dim)) # hidden_dim -> hidden_dim\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(hidden_dim, 1)) # hidden_dim -> 1\n",
    "        self.net = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        coordination = self.net(x)\n",
    "        return coordination"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "5acae8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we would like to train our model. \n",
    "\n",
    "We will make a change compared to the training loop that we have used before, \n",
    "motivated by us having a lot of data now. \n",
    "\n",
    "Previously we have calculated the gradient of the loss calculated across all of our data. \n",
    "When we have relatively few training examples this is fine. This is standard gradient descent.\n",
    "\n",
    "Instead we will now use **stochastic** gradient descent, where the stochastic (random) element \n",
    "comes from computing the gradient over smaller subsets of the data rather than the full dataset \n",
    "for each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b253f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def training_loop(model, X_train, y_train, epochs=1000, lr=1e-3, batch_size=64):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Create a DataLoader: Helps us iterate over the data in batches\n",
    "    loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)): # An epoch is a complete pass through the dataset.\n",
    "        for xb, yb in loader: # xb and yb are the batches of X_train and y_train.\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred.flatten(), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoordinationNumberModel(vector_dim=16)\n",
    "\n",
    "training_loop(model, X_fingerprint, y_tensor, epochs=100, lr=1e-2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "\n",
    "y_pred = model(X_fingerprint).detach().numpy().flatten()\n",
    "\n",
    "ax.scatter(y_tensor, y_pred, s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "e681fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "You won't get perfect predictions, but you should get something that has a decent correlation.\n",
    "\n",
    "Probably a better way of making a model for this property would be a classification model - because the \n",
    "predictions are discrete. (So if you want to, you can make such a model using code from the previous exercise about classification.)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "fd8df70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can easily use the model for atoms in configurations with different sizes. \n",
    "\n",
    "Use the model on a different dataset with more atoms, loaded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cart_9, Y_9 = get_atomic_dataset(9, threshold=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35507ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the fingerprints\n",
    "# Make predictions with the model\n",
    "# Plot the predictions against the true values"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "c2745082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "2cb16409",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example: Atomic energy model."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "5f82381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we will build a model for learning the total energy of atomic configurations using these atomic descriptors.\n",
    "\n",
    "To do so, we will build a model that learns an \"atomic energy\", using the ansatz that the total energy of a \n",
    "configuration can be approximated as\n",
    "\n",
    "$$\n",
    "E_{tot} = \\sum_{i}^N E_i\n",
    "$$\n",
    "\n",
    "Where $E_i$ is the local energy of the i'th atom. \n",
    "\n",
    "The cell below defines a neural network for this task, note the `forward` method is more \n",
    "complicated than we have seen before so some explanation is in order. \n",
    "First, the inputs to forward are\n",
    "\n",
    "- `x`: This is a matrix of atomic descriptors where each row is an atom and the columns are the features. Or in other words it has shape (number of atoms, number of features).\n",
    "- `config_indices`: This is an array with (number of atoms)-entries, that denotes which configuration this atom corresponds to. \n",
    "- `print_shapes`: This is just a switch to be used to print the shapes of the internal parameters.\n",
    "- `return_atomic_energy`: Switch to return atomic energies in addition to the total energy.\n",
    "\n",
    "With that we can describe what happens in the `forward` method\n",
    "\n",
    "1. The atomic energies are predicted by passing the atomic descriptors through the neural network.\n",
    "\n",
    "2. The total energy is computed as the sum of the atomic energy for each configuration. The `batch_sum`-method \n",
    "does this by summing together the atomic energy terms that have the same number in the `config_indices`-array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75205460",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vector_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(torch.nn.Linear(vector_dim, hidden_dim)) # vector_dim -> hidden_dim\n",
    "        layers.append(torch.nn.SiLU())\n",
    "        layers.append(torch.nn.Linear(hidden_dim, hidden_dim)) # hidden_dim -> hidden_dim\n",
    "        layers.append(torch.nn.SiLU())\n",
    "        layers.append(torch.nn.Linear(hidden_dim, 1)) # hidden_dim -> 1\n",
    "        self.net = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def batch_sum(self, atomic_energies, config_indices):        \n",
    "        n_configs = torch.unique(config_indices).shape[0]\n",
    "        total_energy = torch.zeros(n_configs)\n",
    "        for i in range(n_configs):\n",
    "            mask = config_indices == i\n",
    "            total_energy[i] = atomic_energies[mask].sum()\n",
    "        return total_energy\n",
    "\n",
    "    def forward(self, x, config_indices, print_shapes=False, return_atomic_energy=False):\n",
    "        atomic_energy = self.net(x)\n",
    "        total_energy = self.batch_sum(atomic_energy, config_indices)\n",
    "\n",
    "        if print_shapes:\n",
    "            print(\"Input\", x.shape)\n",
    "            print(\"Atomic Energy\", atomic_energy.shape)\n",
    "            print(\"Total Energy\", total_energy.shape)\n",
    "\n",
    "        if not return_atomic_energy:\n",
    "            return total_energy\n",
    "        else:\n",
    "            return total_energy, atomic_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "889a1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "The next two cells define the training loop and a method to get the dataset \n",
    "in an appropriate format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d7dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, X_train, index_train, y_train, epochs=200, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    loss_per_epoch = torch.zeros(epochs)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)): # Loop over the dataset multiple times\n",
    "        optimizer.zero_grad()   # Zero the gradients\n",
    "\n",
    "        # Compute loss for the whole dataset as a batch\n",
    "        E = model.forward(X_train, index_train).squeeze() # Compute the energy\n",
    "        loss = loss_fn(E, y_train)\n",
    "\n",
    "        # Compute gradient and update        \n",
    "        loss.backward()         # Compute the gradient\n",
    "        optimizer.step()        # Update the parameters\n",
    "        loss_per_epoch[epoch] = loss.item() / len(X_train) # Store the loss\n",
    "        \n",
    "    return loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d7c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, X_train, index_train, y_train, epochs=200, lr=0.01, batch_size=32):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    loss_per_epoch = torch.zeros(epochs)\n",
    "\n",
    "    unique_index_train = torch.unique(index_train)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(unique_index_train),\n",
    "        batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    for epoch in tqdm(range(epochs)): # Loop over the dataset multiple times\n",
    "        optimizer.zero_grad()   # Zero the gradients\n",
    "\n",
    "        for (index_batch,) in loader:\n",
    "\n",
    "            mask = torch.isin(index_train, index_batch)\n",
    "            X_batch = X_train[mask]\n",
    "            y_batch = y_train[index_batch]\n",
    "            index_batch = index_train[mask]\n",
    "        \n",
    "            # Compute loss for the whole dataset as a batch\n",
    "            E_batch = model.forward(X_batch, index_batch).squeeze() # Compute the energy\n",
    "            loss = loss_fn(E_batch, y_batch)\n",
    "\n",
    "            # Compute gradient and update        \n",
    "            loss.backward()         # Compute the gradient\n",
    "            optimizer.step()        # Update the parameters\n",
    "            loss_per_epoch[epoch] += loss.item()\n",
    "\n",
    "        loss_per_epoch[epoch] /= len(loader)\n",
    "        \n",
    "    return loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd40290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(n_atoms, max_examples=None):\n",
    "    fingerprints = []\n",
    "    n_atoms_list = []\n",
    "    energies = []\n",
    "    for n in n_atoms:  \n",
    "        X, E = get_carbon_cluster_data(n, max_examples=max_examples)\n",
    "        fingerprints.extend([torch.tensor(atomic_fingerprint(x)).float() for x in X])\n",
    "        n_atoms_list.extend([x.shape[0] for x in X])\n",
    "        energies.extend(E)\n",
    "\n",
    "    fingerprints = torch.vstack(fingerprints)\n",
    "    energies = torch.tensor(np.array(energies))\n",
    "\n",
    "    config_indices = torch.zeros(len(fingerprints), dtype=torch.int64)\n",
    "    start = 0; c = 0\n",
    "    for n in n_atoms_list:\n",
    "        config_indices[start:start+n] = c\n",
    "        start += n\n",
    "        c += 1\n",
    "\n",
    "    return fingerprints, energies, config_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "e5d71898",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we can test that everything works as we would like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fingerprints, train_energies, train_config_indices = get_dataset([6]) # Only configurations with 6 atoms.\n",
    "model = NeuralNetworkModel(train_fingerprints[0].shape[-1]) \n",
    "prediction = model(train_fingerprints, train_config_indices, print_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetworkModel(vector_dim=train_fingerprints[0].shape[-1])\n",
    "loss_history = training_loop(model, \n",
    "                             train_fingerprints, \n",
    "                             train_config_indices, \n",
    "                             train_energies, \n",
    "                             epochs=10000, \n",
    "                             lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.plot(loss_history)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "a4af1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "As a test set we will now use configurations with 7 atoms. \n",
    "\n",
    "Remember that the model was only trained on configurations with 6 atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fingerprints, test_energies, test_config_indices = get_dataset([7]) # Only configurations with 6 atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47de6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imlms.potentials.plot_parity import plot_parity\n",
    "\n",
    "E_pred_train = model(train_fingerprints, train_config_indices).detach().numpy()\n",
    "\n",
    "E_pred_test = model(test_fingerprints, test_config_indices).detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3), layout=\"constrained\")\n",
    "plot_parity(ax[0], train_energies, E_pred_train)\n",
    "ax[0].set_title('Train')\n",
    "\n",
    "plot_parity(ax[1], test_energies, E_pred_test)\n",
    "ax[1].set_title('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "239e9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "The model performs rather well on the training set, but not so well on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "d86149e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise: Model trained on differently sized configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "8f961a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "This loads the data for clusters of sizes betwee 6 and 8 atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fingerprints, train_energies, train_config_indices = get_dataset([6, 7, 8], max_examples=100) # Configurations with 6 and 7 atoms."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "aa1b6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train the model using this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6161cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.plot(loss_history)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "1ea5ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can test the model on clusters of several different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fingerprints, test_energies, test_config_indices = get_dataset([6, 7, 8, 9, 10], max_examples=None) # Only configurations with 6 atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d8ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imlms.potentials.plot_parity import plot_parity\n",
    "\n",
    "E_pred_train = model(train_fingerprints, train_config_indices).detach().numpy()\n",
    "\n",
    "E_pred_test = model(test_fingerprints, test_config_indices).detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3), layout=\"constrained\")\n",
    "plot_parity(ax[0], train_energies, E_pred_train)\n",
    "ax[0].set_title('Train')\n",
    "\n",
    "plot_parity(ax[1], test_energies, E_pred_test)\n",
    "ax[1].set_title('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2768615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
